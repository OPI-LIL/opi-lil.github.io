---
layout: post
title: "Polish Keywords Extraction Method"
description: "Extracting keywords automatically from a given Polish text"
category: [NLP]
tags: [NLP, Text Mining]
---

In this post a novel summarization approach is presented, called **Polish Keywords Extractor (PKE)**, which is the single document oriented method that is capable of extracting keywords from Polish documents. **PKE** is a knowledge-poor method (not using any external knowledge resources as Wikipedia) inspired by **KEA** [1] and **RAKE** [2]. 

<!--more-->

In contrast to previous methods **PKE** uses Polish lemmatizer, Part-of-Speech filters, and various evaluation approaches (statistical measures, classifiers). This algorithm was tested on a set of abstracts of Polish academic papers. The experiments have shown that **PKE** achieves better quality measures (precision, recall, F-measure) than either **KEA**[1] or **RAKE** [2].

**PKE** starts with splitting text into sentences. Each sentence is represented as a sequence of words. Next words are normalized (lemmatized) and tagged with Part-of-Speech properties. Keyword candidates selection is performed in order to find a finite number of potential significant words. Finally, candidates are evaluated by previously built models (bayesian classifier or statistic function), subsequently highest scoring candidates are retrieved. 

**Keyword candidate selection approaches**

Pattern-Recursive selector is based on four ordered PoS patterns. First, from a sentence are removed stopwords, words containing none-alphanumeric items, words, which are not nouns, adjectives, or unknown PoS. Next there is invoked recursive finder, which searches for candidates using four priority patterns (noun-adjective, noun-unknown, noun-noun, noun). When it identifies phrase matching one of these patterns then sentence is splitted and subsentences are recursively searched in the same manner. In this way potential candidates are identified. Additionally for each candidate (if its size is more than one word)subcombinations are generated, which are checked by abovementioned PoS patterns. Subcombinations extends list of potential keywords.

PoS selector is based on the pattern described by the complex regular expression. Text is splitted into sequences of contiguous words at phrase delimiters and stop word positions. Afterwards, for each candidate its subcombinations are built, which extend number of potential keywords. All of potential keywords are filtered out by the PoS regular expression: *(noun)(noun|adjective|unknown)**.

**Keyword candidate evaluation approaches**

Evaluation may be done in two modes – supervised (classifier) and unsupervised (statistic function). 
	
Supervised approach is based on classifiers. Each candidate is categorized as proper or unproper keyword. Candidates are described by vectors of four features (all features are normalized to one): 

 - **tf-idf** – term frequency is counted for a candidate in the processed abstract, inverse document frequency is counted within training set;  
 - **first occurrence in an abstract** – a position of the first candidate's occurrence in a processed abstract;  
 - **first occurrence in a sentence** – a position of the first candidate's occurrence within a sentence;  
 - **size** – number of member's words contained in a keyword.

In training phase, in an effort to identify proper keywords, classifier is learned. During candidate validation process probabilities of being a proper/unproper keyphrase are measured. The highest of them implies category. Probabilities of being a proper keyword are used to sort candidates and retrieve only limited number of them.

Unsupervised evaluation approach is based on scoring function $freq(w)^2$. Compound keyword's scores are the sum of its member's scores. This formula provides better results than Rake's one – $deg(w)/freq(w)$. Scored candidates are sorted and top $T$ are selected as keywords for the given document.

**Experiments**

Abstracts where downloaded from different web sources (e.g. pubmed, yadda). All abstracts have assigned at least three keywords. All manually assigned keywords tend to appear in a text of abstract (about 83% of keywords are directly placed within a text of abstract). Abstracts were divided randomly into training set (about 9000 documents) and validation set (about 3000 documents). Tests were taken on validation set.
	
We choose abstracts instead of full text articles for two reasons. First of all, it is much easier to automaticly download abstracts from digital libraries. Most of digital libraries demand authorization to download a whole article, and there is also legal issues concerning saving articles on the private hard disks. The second reason is much more pragmatic, there is a lot of academic papers about articles summarization, but only few of them involve abstracts. You cannot use the same approach for a long text and for a short one, what makes this topic interesting. Moreover, vast majority of texts in the web is rather shorter than longer. We could assume  that our results and methods, built in order to retrieve keywords from abstracts, may be very easily transfered into the web resources.

We validated all possible variants of **PKE**:
 
1. $PKE_1$ – pattern-recursive selector, and unsupervised candidate evaluator;
2. $PKE_2$ – PoS selector, and unsupervised candidate evaluator.
2. $PKE_3$ – pattern-recursive selector, and supervised candidate evaluator;
3. $PKE_4$ – PoS selector, and supervised candidate evaluator;

All those mentioned **PKE** variants were tested against **RAKE** and**KEA**(the maximal limit of retrieved keywords is set on 5). The results are presented below, in the table. 

Algorithm | Precision(%) | Recall(%) | F1(%) 
--- | --- | --- | ---
$RAKE$ | 1,34 | 1,41 | 1,37
$KEA$ | 18,41 | 19,33 | 18,86
$PKE_1$ | 19,11 | 20,06 | 19,57
$PKE_2$ | 16,69 | 17,52 | 17,10
$PKE_3$ | **23,30** | **24,46** | **23,87**
$PKE_4$ | 21,93 | 23,03 | 22,47
 
Pattern-recursive candidate's selector influences on higher precision and recall. Having the same candidate's evaluation method **PKE** with Pattern-recursive selector outperforms **PKE** with PoS selector.  Naive Bayes Classifier is better candidate's evaluation method than unsupervised function. Having the same candidate's selector supervised mode reports higher recall and precision than unsupervised one.  

While comparing **RAKE**, **KEA** and **PKE** one should notice that **PKE** outperformes other methods with regard to error measures. Only in the case of F-Measure **KEA** has a slight edge over **PKE**. In all other cases **PKE** works significantly better. It is worth noticing, that especially supervised variants surpass both **KEA** and **RAKE**. The best results are reported by supervised **PKE** with pattern-recursive candidate selector. 

**In conclusion, it is safe to claim, that **PKE** presents relevant improvements in retrieving Polish keywords**. 

###References
[1]: Witten I.H., Paynter G.W., Frank E., Gutwin C. and Nevill-Manning C.G.: KEA: Practical automatic keyphrase extraction. Working Paper 00/5, Department of Computer Science, The University of Waikato, 2000.

[2]: Rose S., Engel D., Cramer N., Cowley W.: Automatic keyword extraction from individual documents. Text Mining: Applications and Theory, pp.19-37, 2010.